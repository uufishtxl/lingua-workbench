# Lingua Workbench ğŸ§

A personal language learning platform for analyzing and studying spoken English from audio sources like TV shows and movies.

![Audio Slicer Demo](./docs/screenshots/fig_lwb_audio-slicer_complete-editing.png)

## âœ¨ Features

### ğŸµ Audio Management
- **Source Audio Upload**: Upload audio files organized by drama/season/episode
- **Auto Chunking**: Automatically splits long audio into 5-minute chunks
- **Waveform Visualization**: Interactive waveform with region selection

### âœ‚ï¸ Audio Slicing & Annotation
- **Region Selection**: Click and drag on waveform to create audio slices
- **Whisper Transcription**: AI-powered speech-to-text transcription
- **Text Highlighting**: Select text to create highlights for deeper analysis

![Transcription](./docs/screenshots/fig_lwb_audio-slicer_transcribe-text.png)

### ğŸ”Š Sound Script Analysis
Sound Script provides AI-generated phonetic breakdown of spoken phrases, showing how words are actually pronounced in connected speech:

| Tag | ä¸­æ–‡ | Description |
|-----|------|-------------|
| Reduction | å¼±åŒ– | Vowel reduced to schwa |
| Linking | è¿è¯» | Consonant-vowel linking across words |
| Assimilation | åŒåŒ– | Sound changes due to adjacent sounds |
| H-deletion | Håˆ é™¤ | Initial /h/ dropped in function words |
| Flap T | é—ªéŸ³T | T/D flapped between vowels |
| Glottal Stop | å–‰å¡éŸ³ | T replaced with glottal stop |

**Sound Display Notation**:
- Phonetic spelling (e.g., "wuh-duh-we" for "what do we")
- ~~Strikethrough~~ for ghost/silent sounds
- Ruby text showing pronunciation above original text

![AI Sound Analysis](./docs/screenshots/fig_lwb_audio-slicer_ai-sound-result.png)

### ğŸ“– Dictionary Integration
- **AI Dictionary Lookup**: Context-aware definitions for words/phrases
- **Bilingual Examples**: Example sentences in both English and Chinese
- **Example Refresh**: Generate new contextual examples on demand

![AI Dictionary](./docs/screenshots/fig_lwb_audio-slicer_ai-definition-result.png)

### ğŸ› ï¸ Editing Capabilities
- **Dual Edit Modes**: 
  - **AI Note Mode**: Edit phonetic tags and notes
  - **Sound Display Mode**: Correct AI's pronunciation analysis
- **Time Adjustment**: Fine-tune slice boundaries with Â±0.5s arrows
- **Favorite Marking**: Star important sentences for review

![Edit Mode](./docs/screenshots/fig_lwb_audio-slicer_edit-transcription.png)

### ğŸ›ï¸ Playback Controls
- **Variable Speed**: 0.5x - 1.5x playback speeds
- **Loop Playback**: Repeat audio regions for practice
- **Region Playback**: Click to play individual slices

## ğŸ—ï¸ Tech Stack

### Frontend
| Technology | Purpose |
|------------|---------|
| Vue 3 | UI framework with Composition API |
| TypeScript | Type-safe JavaScript |
| Vite | Build tool and dev server |
| Element Plus | UI component library |
| Tailwind CSS | Utility-first CSS |
| WaveSurfer.js | Audio waveform visualization |
| Pinia | State management |
| Axios | HTTP client |

### Backend
| Technology | Purpose |
|------------|---------|
| Django | Web framework |
| Django REST Framework | API development |
| SimpleJWT | JWT authentication |
| LangChain | LLM orchestration |
| OpenAI API | AI analysis and dictionary |

### Services
| Service | Purpose |
|---------|---------|
| Whisper API | Speech-to-text transcription |
| OpenAI GPT-4 | Phonetic analysis and examples |

## ğŸ“ Project Structure

```
lingua-workbench/
â”œâ”€â”€ frontend/                # Vue 3 frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/            # API client functions
â”‚   â”‚   â”œâ”€â”€ components/     # Vue components
â”‚   â”‚   â”œâ”€â”€ views/          # Page views
â”‚   â”‚   â””â”€â”€ stores/         # Pinia stores
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/                 # Django backend
â”‚   â”œâ”€â”€ audio_slicer/       # Audio management app
â”‚   â”œâ”€â”€ ai_analysis/        # AI analysis app
â”‚   â””â”€â”€ requirements.in
â”œâ”€â”€ whisper/                 # Whisper API service
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ dita/               # DITA source files
â”‚   â””â”€â”€ screenshots/        # Product screenshots
â””â”€â”€ playwright-screenshots/  # Automated screenshot tool
```

## ğŸ”§ Developer Documentation

For developers contributing to the codebase, detailed component architecture documentation is available:

| Component | Description | Docs |
|-----------|-------------|------|
| `BaseWaveSurfer` | Waveform visualization & region management | [Architecture](./docs/dita/topics/developer/wavesurfer/c_basewavesurfer.dita) |
| `AudioSlicer` | Region selection workspace & slice persistence | [Architecture](./docs/dita/topics/developer/audioslicer/c_audioslicer.dita) |
| `SliceCard` | Audio slice editing with highlighting & AI | [Architecture](./docs/dita/topics/developer/slicecard/c_slicecard.dita) |

**Composables:**

| Composable | Description | Docs |
|------------|-------------|------|
| `useRecording` | Microphone recording & playback | [Architecture](./docs/dita/topics/developer/composables/c_userecording.dita) |
| `useTranscription` | Whisper API transcription | [Architecture](./docs/dita/topics/developer/composables/c_usetranscription.dita) |
| `useHighlightSelection` | Text selection & highlight creation | [Architecture](./docs/dita/topics/developer/composables/c_usehighlightselection.dita) |

> The waveform is the foundation of all audio interactions. See [jottings/BaseWaveSurfer.md](./jottings/BaseWaveSurfer.md) for detailed API reference.

## ğŸš€ Getting Started

### Prerequisites
- Node.js 20+
- Python 3.11+
- ffmpeg (for audio processing)

### Frontend Setup
```bash
cd frontend
npm install
npm run dev
```

### Backend Setup
```bash
cd backend
python -m venv venv
venv\Scripts\activate  # Windows
pip install -r requirements.txt
python manage.py migrate
python manage.py runserver
```

### Environment Variables
Create `.env` files for both frontend and backend:

**Backend `.env`:**
```
SECRET_KEY=your-secret-key
DEBUG=True
OPENAI_API_KEY=your-openai-key
```

## ğŸ“¸ Screenshots

| Feature | Screenshot |
|---------|------------|
| Audio Slice | ![Slice](./docs/screenshots/fig_lwb_audio-slicer_slice-audio.png) |
| Transcription | ![Transcribe](./docs/screenshots/fig_lwb_audio-slicer_transcribe-text.png) |
| Text Highlight | ![Highlight](./docs/screenshots/fig_lwb_audio-slicer_highlight-text-02.png) |
| Sound Analysis | ![Sound](./docs/screenshots/fig_lwb_audio-slicer_ai-sound-result.png) |
| Dictionary | ![Dict](./docs/screenshots/fig_lwb_audio-slicer_ai-definition-result.png) |
| Completed | ![Complete](./docs/screenshots/fig_lwb_audio-slicer_complete-editing.png) |

## ğŸ“ License

MIT License - See [LICENSE](./LICENSE) for details.

---

*Built for language learners who want to master natural spoken English through authentic audio sources.* ğŸŒŸ
